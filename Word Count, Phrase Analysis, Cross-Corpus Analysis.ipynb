{"cells":[{"cell_type":"markdown","metadata":{"id":"RVPIBjwjx6pO"},"source":["# Word Count, Phrase Analysis, Cross-Corpus Analysis\n","\n","In learning English, there are phrases and words that are overly used and seldom used - it depends on what corpus is being used. Here, we will do word count, phrase analysis and cross-corpus analysis to determine the phrases that are overly used by learners.\n","<br><br>\n","One dataset is taken from [`British National Corpus`](http://www.natcorp.ox.ac.uk/), which is from 100 million word collection of samples of written and spoken language from a wide range of sources, designed to represent a wide cross-section of British English, both spoken and written, from the late twentieth century. Another one is called [`NAIST Lang-8`](https://sites.google.com/site/naistlang8corpora/),a language exchange social networking website geared towards language learners. The website is run by Lang-8 Inc., which is based in Tokyo, Japan.\n","\n","\n","https://drive.google.com/drive/folders/1vtCjRptZL6T4mffzbnqwi5i4WrqVnZHr?usp=sharing\n"]},{"cell_type":"markdown","metadata":{"id":"xotpb7p5x6pd"},"source":["## N-gram counting\n","We will do tokenization and calculation of frequency. The rules of tokenization in this Lab are:\n"," 1. Ignore case (e.g., \"The\" is the same as \"the\")\n"," 2. Split by white spaces <s>and punctuations</s>\n"," 3. Ignore all punctuation\n","<br><br>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33210,"status":"ok","timestamp":1664354907439,"user":{"displayName":"Kevin Yang","userId":"04518680380941289042"},"user_tz":-480},"id":"GC_wab2p2Pam","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8effd836-a073-4c51-b29c-ce6dc926fe61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import re\n","import string\n","from pprint import pprint\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8iLjwEwBx6ph"},"outputs":[],"source":["\n","def tokenize(text):\n","    \"\"\"\n","    Input:\n","    \"This is an example.'\n","\n","    Sample output: \n","    ['this', 'is', 'an', 'example', '.']\n","    \"\"\"  \n","    #### [ TODO ] transform text to lower case\n","    lowerText = text.lower()\n","    pureText = re.sub(r'[.,\"\\'-?:!;]', '', re.sub(r'[0-9]+', '', lowerText))\n","    #### [ TODO ] seperate the words by white space\n","    splitText = pureText.split()\n","    return splitText\n","\n","from collections import Counter\n","\n","def calculate_frequency(tokens):\n","    \"\"\"\n","    Input:\n","    ['this', 'is', 'an', 'example', ...]\n","\n","    Sample output: \n","    {\n","        'the': 79809, \n","        'project': 288,\n","        ...\n","    }\n","    \"\"\"\n","    #### [ TODO ] \n","    topToken = Counter(tokens).most_common()\n","    di = dict(topToken)\n","    return di\n","   \n","def ranking(tokens):\n","    rank = 0\n","    previous_number = 0\n","    for element in tokens:\n","        rank += 1\n","        tokens[element] = rank\n","    return tokens\n","\n","def get_ngram(tokens,n):\n","    ngram_result = []\n","    ngram_list = [tokens[i:i+n] for i in range(0,len(tokens)-1)]\n","    for element in ngram_list:\n","        ngram_result.append(' '.join(element[0 : n]))\n","    return ngram_result\n","\n","    \"\"\"\n","    Input:\n","    ['this', 'is', 'an', 'example', ...]\n","\n","    Sample output: \n","    ['this is', 'is an', 'an example', ...]\n","    \"\"\"\n","    #### [TODO] \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"DzNkb52_b9u3","executionInfo":{"status":"ok","timestamp":1664355604077,"user_tz":-480,"elapsed":526,"user":{"displayName":"Kevin Yang","userId":"04518680380941289042"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"61c56336-d35e-42af-aeb3-fb6669abf1bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["['having spent', 'spent half', 'half days', 'days and', 'and full', 'full weeks', 'weeks at', 'at king', 'king henry', 'henry v', 'v school', 'school in', 'in coventry', 'coventry i', 'i feel', 'feel i', 'i can', 'can appreciate', 'appreciate more', 'more what', 'what being', 'being a', 'a teacher', 'teacher is', 'is like', 'like the', 'the challenges', 'challenges and', 'and every', 'every day', 'day tasks', 'tasks they', 'they face', 'face and', 'and how', 'how relevant', 'relevant some', 'some of', 'of the', 'the aspects', 'aspects of', 'of learning', 'learning that', 'that we', 'we had', 'had studied', 'studied were', 'were to', 'to the', 'the way', 'way the', 'the pupils', 'pupils there', 'there learnt', 'learnt i', 'i spent', 'spent a', 'a lot', 'lot of', 'of my', 'my time', 'time observing', 'observing teachers', 'teachers but', 'but also', 'also did', 'did some', 'some teaching', 'teaching myself', 'myself which', 'which included', 'included taking', 'taking over', 'over a', 'a year', 'year class', 'class for', 'for a', 'a period', 'period of', 'of lessons', 'lessons the', 'the first', 'first section', 'section of', 'of this', 'this essay', 'essay is', 'is about', 'about some', 'some of', 'of the', 'the many', 'many different', 'different lessons', 'lessons i', 'i observed', 'observed and', 'and the', 'the second', 'second is', 'is about', 'about my', 'my experiences', 'experiences of', 'of teaching', 'teaching one', 'one of', 'of the', 'the best', 'best lessons', 'lessons i', 'i observed', 'observed was', 'was a', 'a first', 'first lesson', 'lesson on', 'on probability', 'probability taught', 'taught to', 'to a', 'a year', 'year class', 'class the', 'the teacher', 'teacher copied', 'copied a', 'a picture', 'picture of', 'of a', 'a horse', 'horse onto', 'onto the', 'the interactive', 'interactive whiteboard', 'whiteboard and', 'and then', 'then told', 'told the', 'the children', 'children to', 'to imagine', 'imagine a', 'a horse', 'horse race', 'race there', 'there are', 'are horses', 'horses and', 'and which', 'which horse', 'horse moves', 'moves is', 'is determined', 'determined by', 'by the', 'the roll', 'roll of', 'of two', 'two dice', 'dice ie', 'ie if', 'if someone', 'someone rolls', 'rolls a', 'a and', 'and a', 'a horse', 'horse number', 'number three', 'three moves', 'moves the', 'the teacher', 'teacher passed', 'passed the', 'the dice', 'dice around', 'around the', 'the class', 'class and', 'and got', 'got each', 'each child', 'child to', 'to shake', 'shake them', 'them whatever', 'whatever score', 'score they', 'they got', 'got the', 'the teacher', 'teacher would', 'would put', 'put a', 'a cross', 'cross on', 'on the', 'the board', 'board next', 'next to', 'to that', 'that horse', 'horse a', 'a horse', 'horse needed', 'needed crosses', 'crosses to', 'to win', 'win some', 'some children', 'children immediately', 'immediately noticed', 'noticed that', 'that could', 'could not', 'not win', 'win after', 'after about', 'about six', 'six throws', 'throws he', 'he asked', 'asked them', 'them to', 'to bet', 'bet on', 'on what', 'what horse', 'horse they', 'they think', 'think will', 'will win', 'win quite', 'quite a', 'a few', 'few went', 'went for', 'for but', 'but was', 'was doing', 'doing equally', 'equally as', 'as well', 'well at', 'at the', 'the time', 'time which', 'which encouraged', 'encouraged some', 'some to', 'to go', 'go for', 'for that', 'that but', 'but at', 'at least', 'least one', 'one person', 'person went', 'went for', 'for everything', 'everything this', 'this caused', 'caused much', 'much excitement', 'excitement with', 'with people', 'people cheering', 'cheering for', 'for their', 'their number', 'number i', 'i now', 'now realise', 'realise that', 'that in', 'in this', 'this lesson', 'lesson the', 'the teacher', 'teacher is', 'is following', 'following the', 'the constructivism', 'constructivism model', 'model of', 'of learning', 'learning []', '[] says', 'says that', 'that methods', 'methods likely', 'likely to', 'to feature', 'feature heavily', 'heavily in', 'in the', 'the constructivist', 'constructivist teaching', 'teaching approach', 'approach are', 'are practical', 'practical work', 'work structural', 'structural apparatus', 'apparatus discovery', 'discovery learning', 'learning and', 'and investigative', 'investigative methods', 'methods this', 'this activity', 'activity encapsulated', 'encapsulated many', 'many of', 'of these', 'these it', 'it turned', 'turned out', 'out that', 'that won', 'won but', 'but as', 'as expected', 'expected the', 'the results', 'results formed', 'formed a', 'a standard', 'standard normal', 'normal curve', 'curve in', 'in the', 'the last', 'last minutes', 'minutes he', 'he asked', 'asked for', 'for the', 'the classes', 'classes mathematical', 'mathematical thoughts', 'thoughts on', 'on the', 'the results', 'results he', 'he listened', 'listened to', 'to them', 'them all', 'all and', 'and although', 'although he', 'he corrected', 'corrected them', 'them on', 'on some', 'some of', 'of the', 'the language', 'language used', 'used he', 'he did', 'did not', 'not correct', 'correct wrong', 'wrong hypotheses', 'hypotheses to', 'to start', 'start with', 'with this', 'this is', 'is an', 'an example', 'example of', 'of a', 'a high', 'high degree', 'degree of', 'of interaction', 'interaction between', 'between pupils', 'pupils and', 'and teacher', 'teacher []', '[] which', 'which is', 'is seen', 'seen as', 'as a', 'a very', 'very positive', 'positive thing', 'thing there', 'there was', 'was more', 'more of', 'of this', 'this at', 'at the', 'the end', 'end when', 'when after', 'after drawing', 'drawing a', 'a sample', 'sample space', 'space diagram', 'diagram on', 'on the', 'the board', 'board and', 'and getting', 'getting them', 'them to', 'to fill', 'fill in', 'in the', 'the rows', 'rows he', 'he asked', 'asked them', 'them for', 'for their', 'their thoughts', 'thoughts he', 'he finished', 'finished by', 'by asking', 'asking them', 'them what', 'what they', 'they thought', 'thought the', 'the probability', 'probability of', 'of getting', 'getting a', 'a even', 'even number', 'number and', 'and number', 'number greater', 'greater than', 'than was', 'was when', 'when two', 'two dice', 'dice are', 'are thrown', 'thrown the', 'the lesson', 'lesson also', 'also links', 'links to', 'to bruners', 'bruners learning', 'learning theory', 'theory instruction', 'instruction he', 'he talks', 'talks of', 'of this', 'this having', 'having main', 'main features', 'features and', 'and this']\n"]}],"source":["### data test \n","f = open('/content/drive/MyDrive/test.txt', 'r',encoding=\"utf-8\")\n","fileRead = f.read()\n","#### [ TODO ] generate test unigrams and calculate document frequency of unigram in test\n","test_unigram = tokenize(fileRead)\n","test_bigram = get_ngram(test_unigram,2)\n","print(test_bigram)\n","# test_bigram_counter = calculate_frequency(test_bigram)\n","# lang_unigram_Rank = ranking(test_bigram_counter)\n","# print(lang_unigram_Rank)\n","f.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sj3-ZuWP2Pao"},"outputs":[],"source":["#  file_path = os.path.join('data', 'bnc.txt')\n","f = open('/content/drive/MyDrive/bnc.txt', 'r',encoding=\"utf-8\")\n","fileRead = f.read()\n","#### [ TODO ] generate BNC unigrams and calculate document frequency of unigram in BNC\n","BNC_unigram = tokenize(fileRead)\n","BNC_unigram_counter = calculate_frequency(BNC_unigram)\n","f.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZlkiCuQx6pt"},"outputs":[],"source":["# Read lang-8 Data\n","# file_path = os.path.join('data','lang8.txt')\n","f = open('/content/drive/MyDrive/lang8.txt', 'r',encoding=\"utf-8\")\n","fileRead = f.read()\n","#### [ TODO ] generate lang8 unigrams and calculate document frequency of unigram in lang8\n","lang_unigram = tokenize(fileRead)\n","lang_unigram_counter = calculate_frequency(lang_unigram)\n","f.close()\n"]},{"cell_type":"markdown","metadata":{"id":"lPBceKOax6pt"},"source":["## Rank\n","Rank unigrms by their frequencies. The higher the frequency, the higher the rank. (The most frequent unigram ranks 1.)<br>\n","<span style=\"color: red\">[ TODO ]</span> <u>Rank unigrams for Lang-8 and BNC.</u>."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SH9xlXpBx6pu"},"outputs":[],"source":["#### [ TODO ] Rank unigrams for lang\n","lang_unigram_Rank = ranking(lang_unigram_counter)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rN3MQTebx6pv"},"outputs":[],"source":["#### [ TODO ] Rank unigrams for BNC\n","BNC_unigram_Rank = ranking(BNC_unigram_counter)\n"]},{"cell_type":"markdown","metadata":{"id":"pm26VfkDx6pv"},"source":["## Calculate Rank Ratio\n","In this step, you need to map the same unigram in two dataset, and calculate the Rank Ratio of unigrams.  <br>Please follow the formula for calculating Rank Ratio:<br> \n","<br>\n","\n","$Rank Ratio = \\frac{Rank of BNC }{Rank of Lang8}$\n","<br><br>\n","If the unigram doesn't appear in BNC, the rank of it is treated as 1.\n","\n","<span style=\"color: red\">[ TODO ]</span> Please calculate all rank ratios of unigrams in Lang-8."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNSj6gbU2Paq"},"outputs":[],"source":["#### [ TODO ] Calculate Rank Ratio\n","lang_rank_ratio = {}\n","for element in lang_unigram_Rank:\n","    if(element in BNC_unigram_Rank):\n","        lang_rank_ratio[element] = BNC_unigram_Rank[element]/lang_unigram_Rank[element]\n","    else:\n","        lang_rank_ratio[element] = 1\n","\n","list_lang_rank_ratio = sorted(lang_rank_ratio.items(), key=lambda x: x[1],reverse=True)\n","list_lang_rank_ratio_top = list_lang_rank_ratio[0:30]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7U08oh2Ex6pw"},"source":["## sort the result\n","<span style=\"color: red\">[ TODO ]</span> Please show top 30 unigrams in Rank Ratio and the value of their Rank Ratio in this format: \n","<br>\n","<img src=\"https://scontent-hkt1-2.xx.fbcdn.net/v/t39.30808-6/307940624_756082125461769_4218487831464443689_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=730e14&_nc_ohc=M0u8b1s2wakAX_Mgt7E&_nc_ht=scontent-hkt1-2.xx&oh=00_AT_peeQy_D2UyQYlMWbCIZjQTU7F38SJyE2A09J_SnZ-aA&oe=632E03C0\" width=50%>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhyGW1jC2Paq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664257123156,"user_tz":-480,"elapsed":3,"user":{"displayName":"Kevin Yang","userId":"04518680380941289042"}},"outputId":"208d16de-03fa-4cdc-f9b5-6da4fcca8b8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["  rank  unigram          rankratio\n","------  -------------  -----------\n","     1  doesnt             85.5124\n","     2  internet           72.3168\n","     3  countrys           69.6875\n","     4  opcit              51.9052\n","     5  radstone           50.2724\n","     6  isnt               49.8752\n","     7  uht                49.7557\n","     8  kants              49.1012\n","     9  eu                 49.0184\n","    10  dont               48.4824\n","    11  companys           48.3068\n","    12  anthocyanins       47.6316\n","    13  ibid               43.583\n","    14  japans             43.4812\n","    15  webers             43.1641\n","    16  luthers            41.5939\n","    17  bryman             40.2765\n","    18  ibidp              39.0174\n","    19  womens             38.4173\n","    20  creon              38.0404\n","    21  microneedles       37.292\n","    22  rtas               37.2328\n","    23  didnt              36.6757\n","    24  pneumophila        35.8189\n","    25  globalisation      35.6638\n","    26  roosevelts         35.5508\n","    27  punic              35.05\n","    28  manydown           34.9922\n","    29  chinas             34.8763\n","    30  livy               33.5735\n"]}],"source":["#### [ TODO ] \n","lang_rank_ratio_top_with_rank = []\n","rank = 1\n","for i in range(0,len(list_lang_rank_ratio_top)):\n","    lang_rank_ratio_top_with_rank.append([rank] + list(list_lang_rank_ratio_top[i]))\n","    rank += 1\n","  \n","import itertools\n","from tabulate import tabulate\n","headers = [\"rank\",\"unigram\", \"rankratio\"]\n","print(tabulate(lang_rank_ratio_top_with_rank, headers = headers))"]},{"cell_type":"markdown","metadata":{"id":"nOllPQ9-x6px"},"source":["## for Bigrams\n","<span style=\"color: red\">[ TODO ]</span> Do the Same Thing for Bigrams  \n","Hint:  \n","1. generate all bigrams for BNC / lang8  \n","2. calculate frequency for each bigrams  \n","3. rank bigrams by frequency  \n","4. calculate the rank ratio of each bigram\n","5. print out the top 30 highest rank ratio bigrams  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjBx-rcU2Par"},"outputs":[],"source":["#### [ TODO ] \n","BNC_bigram = get_ngram(BNC_unigram,2)\n","BNC_bigram_counter = calculate_frequency(BNC_bigram)\n","BNC_bigram_Rank = ranking(BNC_bigram_counter)\n","\n","lang_bigram = get_ngram(lang_unigram,2)\n","lang_bigram_counter = calculate_frequency(lang_bigram)\n","lang_bigram_Rank = ranking(lang_bigram_counter)\n","\n","#### [ TODO ] Calculate Rank Ratio\n","langbigram_rank_ratio = {}\n","count = 0\n","for element in lang_bigram_Rank:\n","    if(element in BNC_bigram_Rank):\n","        langbigram_rank_ratio[element] = BNC_bigram_Rank[element]/lang_bigram_Rank[element]\n","    else:\n","        langbigram_rank_ratio[element] = 1\n","\n","list_langbigram_rank_ratio = sorted(langbigram_rank_ratio.items(), key=lambda x: x[1],reverse=True)\n","list_langbigram_rank_ratio_top = list_langbigram_rank_ratio[0:30]\n","\n","langbigram_rank_ratio_top_with_rank = []\n","rank = 1\n","for i in range(0,len(list_langbigram_rank_ratio_top)):\n","    langbigram_rank_ratio_top_with_rank.append([rank] + list(list_langbigram_rank_ratio_top[i]))\n","    rank += 1\n","  \n","headers = [\"rank\",\"bigram\", \"rankratio\"]\n","print(tabulate(langbigram_rank_ratio_top_with_rank, headers = headers))"]},{"cell_type":"markdown","metadata":{"id":"ef-_B3bnx6py"},"source":["## TA's Notes\n","\n","If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1OKbXhcv6E3FEQDPnbHEHEeHvpxv01jxugMP7WwnKqKw/edit#gid=0) to reserve demo time.  \n","The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to e-learn website. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n","<br>Note that **late submission will not be allowed**.  "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}