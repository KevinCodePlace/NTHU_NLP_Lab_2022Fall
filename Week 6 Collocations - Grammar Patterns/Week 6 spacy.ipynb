{"cells":[{"cell_type":"markdown","id":"03db8fca","metadata":{"id":"03db8fca"},"source":["# Week 06: Dependency Parser and spacy\n","The assignment this week is to identify the grammar pattern VERB-PREP-NOUN using two different methods. You will practice the various functionalities of spacy in the process. \n","\n","Data used in this assignment:  \n","https://drive.google.com/file/d/1OIZPsDezgLaBjw3OX30YFyeFkzegtwP8/view?usp=sharing\n","\n","* sentences.s2orc.txt\n","\n","spacy tutorials:  \n","https://www.machinelearningplus.com/spacy-tutorial-nlp/#phrasematcher  \n","https://spacy.io/usage/linguistic-features#entity-linking\n","\n","## Requirements\n","* pandas\n","* spacy\n","\n"]},{"cell_type":"markdown","id":"8da24123","metadata":{"id":"8da24123"},"source":["### Installation of spacy"]},{"cell_type":"code","execution_count":null,"id":"4f503a42","metadata":{"id":"4f503a42","colab":{"base_uri":"https://localhost:8080/"},"outputId":"712fc3a1-0e3d-4838-eeb8-dcb59dc4218c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","2022-10-27 02:00:26.267163: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.1) (3.4.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["! pip install spacy\n","! python -m spacy download en_core_web_sm"]},{"cell_type":"markdown","id":"55d6736c","metadata":{"id":"55d6736c"},"source":["### Read Data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TxBAcnwiS6G3","outputId":"2516aa7a-c778-45b6-e945-5a06f391f88e"},"id":"TxBAcnwiS6G3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"4d97fd4d","metadata":{"id":"4d97fd4d","outputId":"ef3e0af3-dd35-4fa5-a396-944539eb4876","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["                                            sentence\n","0  Meanwhile, an analysis of the literature shows...\n","1  Meanwhile, this list can be supplemented with ...\n","2  At the same time, in many cases, several instr...\n","3  It is not possible to give a systematic assess...\n","4  Correlation was calculated for the years, wher...\n"]}],"source":["import pandas as pd\n","\n","def loadData(path):\n","    with open(path) as f:\n","        sents = []\n","        for line in f.readlines():\n","            line = line.strip(\"\\n\").split(\"\\t\")\n","            sents.append(line[1])\n","    return pd.DataFrame({\"sentence\":sents})\n","data = loadData(\"/content/drive/MyDrive/graduate/nlp/week6/sentences.s2orc.txt\")\n","print(data.head())\n"]},{"cell_type":"code","execution_count":null,"id":"f2c07c81","metadata":{"scrolled":true,"id":"f2c07c81"},"outputs":[],"source":["import re\n","import spacy\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"markdown","id":"aef7d493","metadata":{"id":"aef7d493"},"source":["### Spacy example\n","If you have any probelm, look up the documentation [here](https://spacy.io/usage/linguistic-features)\n"]},{"cell_type":"code","execution_count":null,"id":"998b263c","metadata":{"id":"998b263c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7b85012-3a82-4ca0-9eb9-9a909b8c07cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["The economic situation of the country is on edge , as the stock market crashed causing loss of millions. Citizens who had their main investment in the share-market are facing a great loss. Many companies might lay off thousands of people to reduce labor cost.He began immediately to rant about the gas price .\n"]}],"source":["example_text = \"\"\"The economic situation of the country is on edge , as the stock \n","market crashed causing loss of millions. Citizens who had their main investment \n","in the share-market are facing a great loss. Many companies might lay off \n","thousands of people to reduce labor cost.\n","He began immediately to rant about the gas price .\n","\"\"\"\n","\n","# Remove newline character\n","example_text = re.sub(\"\\n\", '', example_text)\n","example_doc = nlp(example_text)\n","print(example_doc)"]},{"cell_type":"markdown","id":"728770d5","metadata":{"id":"728770d5"},"source":["<font color=\"red\">**[ TODO ]**</font> Please print out the 2nd sentence in the example_text"]},{"cell_type":"code","execution_count":null,"id":"03a85784","metadata":{"scrolled":true,"id":"03a85784","outputId":"a75e7242-de5a-452c-ef61-0079ab8beac5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Citizens who had their main investment in the share-market are facing a great loss.\n"]}],"source":["sents = []\n","[sents.append(sent) for sent in example_doc.sents]\n","# for sent in example_doc.sents:\n","#   sents.append(sent)\n","print(sents[1])"]},{"cell_type":"markdown","id":"02f1e521","metadata":{"id":"02f1e521"},"source":["Let's start with some simple linguistic features we have been dealing with.\n","\n","<font color=\"red\">**[ TODO ]**</font> Please print out the following token features of the first sentence in example_text:  \n","text,  lemma,  POS"]},{"cell_type":"code","source":["for token in sents[0]:\n","    print(token,token.lemma_,token.pos_,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZauRjjJVZng","outputId":"e56be901-aea7-4a71-f2e3-6ad4fde7b214"},"id":"oZauRjjJVZng","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The the DET\n","economic economic ADJ\n","situation situation NOUN\n","of of ADP\n","the the DET\n","country country NOUN\n","is be AUX\n","on on ADP\n","edge edge NOUN\n",", , PUNCT\n","as as SCONJ\n","the the DET\n","stock stock NOUN\n","market market NOUN\n","crashed crash VERB\n","causing cause VERB\n","loss loss NOUN\n","of of ADP\n","millions million NOUN\n",". . PUNCT\n"]}]},{"cell_type":"markdown","id":"82bba130","metadata":{"id":"82bba130"},"source":["<font color=\"red\">**[ TODO ]**</font> Data Process 1: Please run the s2orc data through spacy and store the result in data_doc"]},{"cell_type":"code","source":["doc_sentences = \"\"\n","for index,sentence in enumerate(data.sentence):\n","  if index == 0:\n","    doc_sentences = sentence\n","    continue\n","  doc_sentences = doc_sentences + \" \" + sentence"],"metadata":{"id":"eo6vuDbQuaRP"},"id":"eo6vuDbQuaRP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp.max_length = len(doc_sentences) + 100\n","data_doc = nlp(doc_sentences)"],"metadata":{"id":"0H-Z7xicu3zN"},"id":"0H-Z7xicu3zN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_sents = []\n","[data_sents.append(sent) for sent in data_doc.sents]\n","print(data_sents[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzTkTYqgvZOw","outputId":"4c96393b-3892-4493-fc51-7bfc46a31a6d"},"id":"rzTkTYqgvZOw","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Meanwhile, an analysis of the literature shows that the development of indicators of financial stability has not yet been completed.\n"]}]},{"cell_type":"code","execution_count":null,"id":"3d4fb283","metadata":{"id":"3d4fb283","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0f20073-9c87-41b0-af6f-1e98154d6d84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Meanwhile meanwhile ADV\n",", , PUNCT\n","an an DET\n","analysis analysis NOUN\n","of of ADP\n","the the DET\n","literature literature NOUN\n","shows show VERB\n","that that SCONJ\n","the the DET\n","development development NOUN\n","of of ADP\n","indicators indicator NOUN\n","of of ADP\n","financial financial ADJ\n","stability stability NOUN\n","has have AUX\n","not not PART\n","yet yet ADV\n","been be AUX\n","completed complete VERB\n",". . PUNCT\n"]}],"source":["for token in data_sents[0]:\n","  print(token,token.lemma_,token.pos_,)"]},{"cell_type":"markdown","id":"3aa91c05","metadata":{"id":"3aa91c05"},"source":["### Named Entity Recognition\n","Named Entity: a real-world object, such as a person, location, organization, product, etc., that can be denoted with a proper name.  \n","\n","The following is an example of named entity recognition using spacy"]},{"cell_type":"code","execution_count":null,"id":"5d901938","metadata":{"id":"5d901938","outputId":"235400b8-b792-4b61-f9ef-38e8300e2672","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ada Lovelace PERSON\n","New York GPE\n","Thanksgiving DATE\n","Ada Lovelace PERSON\n","Ada Lovelace PERSON\n","US GPE\n","Thanksgiving DATE\n"]}],"source":["ner_doc = nlp(\"Ada Lovelace was born in New York at Thanksgiving. Ada Lovelace, who is a nice Ada Lovelace, was born in the US at Thanksgiving.\")\n","# Document level\n","for e in ner_doc.ents:\n","  print(e.text,e.label_)"]},{"cell_type":"code","execution_count":null,"id":"545a45fd","metadata":{"id":"545a45fd","outputId":"96312f96-183f-404a-e313-b9a33f8fdb9b","colab":{"base_uri":"https://localhost:8080/","height":87}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Ada Lovelace\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," was born in \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    New York\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," at \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Thanksgiving\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n",". \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Ada Lovelace\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", who is a nice \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Ada Lovelace\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n",", was born in the \n","<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    US\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n","</mark>\n"," at \n","<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Thanksgiving\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n","</mark>\n",".</div></span>"]},"metadata":{}}],"source":["from spacy import displacy\n","displacy.render(ner_doc,style='ent',jupyter=True)"]},{"cell_type":"code","source":["# Document level\n","import string \n","from spacy import displacy\n","# nlp.add_pipe(\"merge_entities\")\n","\n","ner_doc_string = str(ner_doc)\n","for e in reversed(ner_doc.ents): \n","    start = e.start_char\n","    end = start + len(e.text)\n","    ner_doc_string = ner_doc_string[:start] + e.label_ + ner_doc_string[end:]\n","\n","nlp.max_length = len(ner_doc_string) + 100\n","ner_doc = nlp(ner_doc_string)\n","print(ner_doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1T8p5j1Wkyqk","outputId":"f0cc6d40-c72e-41ea-a607-4157ef3bddde"},"id":"1T8p5j1Wkyqk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PERSON was born in GPE at DATE. PERSON, who is a nice PERSON, was born in the GPE at DATE.\n"]}]},{"cell_type":"markdown","id":"6a00997d","metadata":{"id":"6a00997d"},"source":["<font color=\"red\">**[ TODO ]**</font> Data Process 2: Please replace all named entities in data_doc with their labels.  \n","For example,  \n","\"Ada Lovelace was born in New York at Thanksgiving.\" should be adjusted to  \n","\"PERSON was born in GPE at DATE.\""]},{"cell_type":"code","source":["### Before replace Named Entity \n","\n","count = 0\n","for index in range(len(data_doc)):\n","  if str(data_doc[index+1]) == ',' :\n","    print(data_doc[index], end='')\n","  else:\n","    print(data_doc[index], end=' ')\n","  if str(data_doc[index]) == '.':\n","    print('\\n')\n","    count += 1\n","  if count == 10:\n","    break\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3ZwxJdH3wgu","outputId":"3601b134-2332-491a-abe0-87160a17ba88"},"id":"i3ZwxJdH3wgu","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Meanwhile, an analysis of the literature shows that the development of indicators of financial stability has not yet been completed . \n","\n","Meanwhile, this list can be supplemented with instruments of monetary policy, which also have an impact on financial stability . \n","\n","At the same time, in many cases, several instruments are used to reduce financial instability, which contributes to the achievement of various intermediate goals . \n","\n","It is not possible to give a systematic assessment of financial stability and coordinate the use of monetary, macro - prudential and micro - prudential policies in order to reduce systemic risks . \n","\n","Correlation was calculated for the years, where the information is available for both indicators . \n","\n","Table 4 defines the criteria for market and institutional balance of financial stability, formed for the Russian economy . \n","\n","The development of a risk map is necessary in order to determine the objects of regulation . \n","\n","Blowing out a bubble has little effect on the asset itself . \n","\n","In the state, the investment directions are tightly controlled, in private companies, there is a danger of their involvement in various risk schemes . \n","\n","The decrease in IFS in early 2015 is due to a sudden increase in inflation at the end of 2014 . \n","\n"]}]},{"cell_type":"code","execution_count":null,"id":"9200b473","metadata":{"id":"9200b473"},"outputs":[],"source":["### Replace Named Entity \n","import string \n","\n","data_doc_string = str(data_doc)\n","for e in reversed(data_doc.ents): \n","    start = e.start_char\n","    end = start + len(e.text)\n","    data_doc_string = data_doc_string[:start] + e.label_ + data_doc_string[end:]\n","nlp.max_length = len(data_doc_string) + 100\n","data_doc = nlp(data_doc_string)"]},{"cell_type":"code","source":["### After replace Named Entity \n","\n","count = 0\n","for index in range(len(data_doc)):\n","  if str(data_doc[index+1]) == ',':\n","    print(data_doc[index], end='')\n","  else:\n","    print(data_doc[index], end=' ')\n","  if str(data_doc[index]) == '.':\n","    print('\\n')\n","    count += 1\n","  if count == 10:\n","    break\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Y1NeeOj55m4","outputId":"b540973d-8b34-465c-d6d8-0fcf4e566952"},"id":"3Y1NeeOj55m4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Meanwhile, an analysis of the literature shows that the development of indicators of financial stability has not yet been completed . \n","\n","Meanwhile, this list can be supplemented with instruments of monetary policy, which also have an impact on financial stability . \n","\n","At the same time, in many cases, several instruments are used to reduce financial instability, which contributes to the achievement of various intermediate goals . \n","\n","It is not possible to give a systematic assessment of financial stability and coordinate the use of monetary, macro - prudential and micro - prudential policies in order to reduce systemic risks . \n","\n","Correlation was calculated for DATE, where the information is available for both indicators . \n","\n","Table CARDINAL defines the criteria for market and institutional balance of financial stability, formed for the NORP economy . \n","\n","The development of a risk map is necessary in order to determine the objects of regulation . \n","\n","Blowing out a bubble has little effect on the asset itself . \n","\n","In the state, the investment directions are tightly controlled, in private companies, there is a danger of their involvement in various risk schemes . \n","\n","The decrease in ORG in DATE is due to a sudden increase in inflation at DATE . \n","\n"]}]},{"cell_type":"markdown","id":"efa97686","metadata":{"id":"efa97686"},"source":["### Dependency Parser\n","\n","If you have probelms concerning the dependency parser tags, look up the documentation [here](https://universaldependencies.org/en/dep/index.html). \n"]},{"cell_type":"code","execution_count":null,"id":"4ca13c64","metadata":{"id":"4ca13c64","outputId":"ed86b7ed-470a-496d-b629-084f7949adf5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Many companies might lay off thousands of people to reduce labor cost.\n","Many amod\n","companies nsubj\n","might aux\n","lay ROOT\n","off prt\n","thousands dobj\n","of prep\n","people pobj\n","to aux\n","reduce advcl\n","labor compound\n","cost dobj\n",". punct\n"]}],"source":["# Example of Dependency Parser\n","print(sents[2])\n","for token in sents[2]:\n","    print(token.text, token.dep_)"]},{"cell_type":"code","execution_count":null,"id":"cc85cf22","metadata":{"id":"cc85cf22","outputId":"aae27402-7ac7-49eb-a58e-d92978fcbcb8","colab":{"base_uri":"https://localhost:8080/","height":441}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"77b414a0bee44feab625ec9488d78458-0\" class=\"displacy\" width=\"2150\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Many</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">companies</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">might</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">lay</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">off</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">thousands</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">of</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">people</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">to</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PART</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">reduce</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">labor</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">cost.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-4\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1265.0,266.5 L1273.0,254.5 1257.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-8\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-77b414a0bee44feab625ec9488d78458-0-10\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-77b414a0bee44feab625ec9488d78458-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1970.0,266.5 L1978.0,254.5 1962.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"]},"metadata":{}}],"source":["from spacy import displacy\n","\n","displacy.render(sents[2], style=\"dep\",jupyter=True)"]},{"cell_type":"markdown","id":"cb6e1a82","metadata":{"id":"cb6e1a82"},"source":["To traverse a dependency tree, use the following properties of token object.  \n","token.children, token.lefts, token.rights  \n","\n","If you have any probelms, please check [here](https://spacy.io/api/token#children)"]},{"cell_type":"markdown","id":"75901966","metadata":{"id":"75901966"},"source":["<font color=\"red\">**[ TODO ]**</font> Please identify a VERB-PREP-NOUN grammar structure in sent[2] by traversing the dependency tree.  \n","Expected output:  \n","(lay, off, thousands)\n"]},{"cell_type":"code","execution_count":null,"id":"9cec92b7","metadata":{"id":"9cec92b7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb60fff8-08d2-4f7e-d4c0-17da00130dff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Many companies might lay off thousands of people to reduce labor cost.\n","{'lay': [(lay, off, thousands)]}\n","[(lay, off, thousands)]\n"]}],"source":["grammar_structure = {}\n","print(sents[2])\n","for token in sents[2]:\n","    if token.pos_ == 'VERB' and str(token.nbor(1).pos_) == 'ADP' and str(token.nbor(2).pos_) == 'NOUN':\n","      if token.lemma_ not in grammar_structure:\n","          grammar_structure[token.lemma_] = [(token,token.nbor(1),token.nbor(2))]\n","      else:\n","        grammar_structure[token.lemma_].append((token,token.nbor(1),token.nbor(2)))\n","      \n","    else:\n","      if token.pos_ == 'VERB':\n","        token_verb_rights = [right for right in token.rights]\n","        for token_verb_right in token_verb_rights:\n","          if str(token_verb_right.pos_) == 'ADP':\n","            verb_next_rights = [right for right in token_verb_right.rights]\n","            for verb_next_right in verb_next_rights:\n","              if str(verb_next_right.pos_) == 'NOUN':\n","                if token.lemma_ not in grammar_structure:\n","                  grammar_structure[token.lemma_] = [(token,token_verb_right,verb_next_right)]\n","                else:\n","                  grammar_structure[token.lemma_].append((token,token_verb_right,verb_next_right))\n","       \n","print(grammar_structure)\n","print(grammar_structure['lay'])"]},{"cell_type":"markdown","id":"1f4e46d2","metadata":{"id":"1f4e46d2"},"source":["<font color=\"red\">**[ TODO ]**</font>  Please identify all VERB-PREP-NOUN grammar structure in data_doc by traversing the dependency trees and save the results in a list of tuples dep_gp.\n"]},{"cell_type":"code","source":["dep_gp = {}\n","structure_count = 0\n","for sentence in data_sents:\n","  for token in sentence:\n","    if token.pos_ == 'VERB' and str(token.nbor(1).pos_) == 'ADP' and str(token.nbor(2).pos_) == 'NOUN':\n","      if token.lemma_ not in dep_gp:\n","          dep_gp[token.lemma_] = [(token,token.nbor(1),token.nbor(2))]\n","      else:\n","        dep_gp[token.lemma_].append((token,token.nbor(1),token.nbor(2)))\n","      structure_count += 1 \n","    else:\n","      if token.pos_ == 'VERB':\n","        token_verb_rights = [right for right in token.rights]\n","        for token_verb_right in token_verb_rights:\n","          if str(token_verb_right.pos_) == 'ADP':\n","            verb_next_rights = [right for right in token_verb_right.rights]\n","            for verb_next_right in verb_next_rights:\n","              if str(verb_next_right.pos_) == 'NOUN':\n","                structure_count += 1 \n","                if token.lemma_ not in dep_gp:\n","                  dep_gp[token.lemma_] = [(token,token_verb_right,verb_next_right)]\n","                else:\n","                  dep_gp[token.lemma_].append((token,token_verb_right,verb_next_right))\n","                \n","print('total keywords:',len(dep_gp))\n","print('total v-prep-n number:',structure_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3P67btg6NQ1d","outputId":"6992a146-8aa7-459d-9c4a-af9935a8acae"},"id":"3P67btg6NQ1d","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total keywords: 1098\n","total v-prep-n number: 7149\n"]}]},{"cell_type":"code","source":["dict(list(dep_gp.items())[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D69skWza6v0O","outputId":"3bfd29ca-7f0f-4280-de5c-524982355f15"},"id":"D69skWza6v0O","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'supplement': [(supplemented, with, instruments)],\n"," 'contribute': [(contributes, to, achievement),\n","  (contribute, to, harmonics),\n","  (contribute, to, luminance),\n","  (contribute, to, cancer),\n","  (contribute, to, generation),\n","  (contributes, to, mechanism),\n","  (contributing, to, flux),\n","  (contributes, to, stability),\n","  (contribute, to, carcinogenesis),\n","  (contribute, to, development),\n","  (contributing, to, development),\n","  (contributes, to, block),\n","  (contributed, to, injury),\n","  (contributed, to, results),\n","  (contribute, to, signal),\n","  (contribute, at, densities),\n","  (contribute, to, variation),\n","  (contribute, to, growth),\n","  (contribute, to, difference),\n","  (contribute, to, response),\n","  (contributed, to, magnitude),\n","  (contributed, to, detection),\n","  (contribute, to, ontology),\n","  (contribute, to, standardisation),\n","  (contribute, to, output),\n","  (contribute, towards, challenge),\n","  (contributing, to, differentiation),\n","  (contribute, to, development),\n","  (contribute, to, momentum),\n","  (contribute, to, goals),\n","  (contribute, to, goals),\n","  (contribute, to, enhancement),\n","  (contribute, to, consequences),\n","  (contribute, to, packet),\n","  (contribute, towards, understanding),\n","  (contribute, to, shifts),\n","  (contributed, until, date),\n","  (contribute, to, literature),\n","  (contribute, to, spectra),\n","  (contribute, to, differences),\n","  (contributes, to, formation),\n","  (contributed, for, devastation)],\n"," 'coordinate': [(coordinate, in, order)]}"]},"metadata":{},"execution_count":122}]},{"cell_type":"markdown","id":"3e4b5c69","metadata":{"id":"3e4b5c69"},"source":["<font color=\"red\">**[ TODO ]**</font>  Please print out all VERB-PREP-NOUN grammar patterns in dep_gp with the verb \"provide\".\n"]},{"cell_type":"code","execution_count":null,"id":"48da0488","metadata":{"id":"48da0488","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2026bda0-63f5-45dd-a74a-946ba114d653"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(provided, by, government),\n"," (provided, by, companies),\n"," (provided, for, system),\n"," (provided, for, variable),\n"," (provide, into, superconductivity),\n"," (provide, at, scale),\n"," (provide, to, reasoning),\n"," (provide, to, issues),\n"," (provides, for, expansion),\n"," (provide, on, models),\n"," (provides, at, sites),\n"," (provides, to, surface),\n"," (provided, by, T),\n"," (provide, in, sections),\n"," (provided, by, methods),\n"," (provide, through, forums),\n"," (provides, with, source),\n"," (provide, with, incentives),\n"," (provided, in, figure),\n"," (provide, for, wave),\n"," (providing, to, system),\n"," (provide, into, importance),\n"," (provide, with, practice),\n"," (provided, by, O),\n"," (provided, for, cultivation),\n"," (provides, to, students),\n"," (provide, from, depth),\n"," (provided, in, pieces),\n"," (provide, with, suggestions),\n"," (provided, on, types),\n"," (provide, with, way),\n"," (provide, for, systems),\n"," (provides, to, walls),\n"," (provided, during, period),\n"," (providing, with, accuracy),\n"," (provide, for, hole),\n"," (provide, to, participants),\n"," (provide, at, level),\n"," (provide, via, language),\n"," (provides, for, languages),\n"," (provided, with, sample),\n"," (provided, with, sample),\n"," (provides, on, parameters),\n"," (provided, by, system),\n"," (provided, into, basis),\n"," (provided, by, levels),\n"," (provided, in, cells),\n"," (provided, into, structure),\n"," (provided, with, respect),\n"," (provided, by, authors),\n"," (provided, by, elements),\n"," (provide, to, patient),\n"," (provided, to, algorithms),\n"," (provide, in, mechanisms),\n"," (provided, by, algorithms),\n"," (provide, in, terms),\n"," (provide, in, line),\n"," (provides, for, subgroups),\n"," (provide, to, pool),\n"," (provided, by, plasma),\n"," (provides, in, populations),\n"," (provided, under, planning),\n"," (provides, as, approach),\n"," (provides, per, patient),\n"," (provided, at, gates),\n"," (provides, in, query),\n"," (providing, in, systems),\n"," (provide, due, restrictions),\n"," (provide, with, respect),\n"," (provides, in, future)]"]},"metadata":{},"execution_count":132}],"source":["dep_gp['provide']"]},{"cell_type":"markdown","id":"5ee87eef","metadata":{"id":"5ee87eef"},"source":["### Rule Based Methods \n","We can also custom build rules for spacy to match patterns.  \n","[Documentation](https://spacy.io/api/matcher)"]},{"cell_type":"code","execution_count":null,"id":"74664296","metadata":{"id":"74664296"},"outputs":[],"source":["from spacy.matcher import Matcher "]},{"cell_type":"code","execution_count":null,"id":"abc9b3d4","metadata":{"id":"abc9b3d4"},"outputs":[],"source":["# Example text\n","text = \"\"\"I visited Manali last time . Around same budget trips ? I was visiting Ladakh this summer . I have planned visiting New York and other abroad places for next year. Have you ever visited Kodaikanal? \"\"\"\n","text = re.sub('\\n', '', text)\n","match_doc = nlp(text)"]},{"cell_type":"code","execution_count":null,"id":"9d053b2f","metadata":{"id":"9d053b2f","outputId":"6de8eaa0-0d41-46b9-a27f-7cf99b8adf50","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":[" matches found: 4\n","Match found: visited Manali\n","Match found: visiting Ladakh\n","Match found: visiting New\n","Match found: visited Kodaikanal\n"]}],"source":["# Initialize the matcher\n","matcher = Matcher(nlp.vocab)\n","\n","# Write a pattern that matches a form of \"visit\" + place\n","my_pattern = [{\"LEMMA\": \"visit\"}, {\"POS\": \"PROPN\"}]\n","\n","# Add the pattern to the matcher and apply the matcher to the doc\n","matcher.add(\"Visting_places\", [my_pattern])\n","matches = matcher(match_doc)\n","\n","# Counting the no of matches\n","print(\" matches found:\", len(matches))\n","\n","# Iterate over the matches and print the span text\n","for match_id, start, end in matches:\n","    print(\"Match found:\", match_doc[start:end].text)"]},{"cell_type":"markdown","id":"065b258c","metadata":{"id":"065b258c"},"source":["<font color=\"red\">**[ TODO ]**</font> Please identify all VERB-PREP-NOUN grammar structure in data_doc by applying a matcher rule and store the results in a list of tuples rule_gp. \n"]},{"cell_type":"code","execution_count":null,"id":"7076373d","metadata":{"id":"7076373d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd2faa61-7504-47a0-d5c3-f4ce0b63df86"},"outputs":[{"output_type":"stream","name":"stdout","text":[" matches found: 1114\n"]}],"source":["rule_gp = {}\n","# Initialize the matcher\n","matcher = Matcher(nlp.vocab)\n","\n","# Write a pattern that matches a form of \"visit\" + place\n","my_pattern = [{\"POS\": \"VERB\"}, {\"POS\": \"ADP\"},{\"POS\": \"NOUN\"}]\n","\n","# Add the pattern to the matcher and apply the matcher to the doc\n","matcher.add(\"Verb_Prep_Noun\", [my_pattern])\n","matches = matcher(data_doc)\n","\n","# Counting the no of matches\n","print(\" matches found:\", len(matches))\n","\n","# Iterate over the matches and print the span text\n","for match_id, start, end in matches:\n","  verb = data_doc[start:end].text.split()[0]\n","  prep = data_doc[start:end].text.split()[1]\n","  noun = data_doc[start:end].text.split()[2]\n","  if verb not in rule_gp:\n","    rule_gp[verb] = [(verb,prep,noun)]\n","  else:\n","    rule_gp[verb].append((verb,prep,noun))\n","    "]},{"cell_type":"code","source":["dict(list(rule_gp.items())[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7l6zyFtgUkb5","outputId":"ebf930d0-1c73-4704-913c-68bf7197fbc0"},"id":"7l6zyFtgUkb5","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'supplemented': [('supplemented', 'with', 'instruments'),\n","  ('supplemented', 'with', 'ORG')],\n"," 'made': [('made', 'in', 'order'),\n","  ('made', 'of', 'particle'),\n","  ('made', 'by', 'researchers'),\n","  ('made', 'among', 'ORG'),\n","  ('made', 'by', 'particle'),\n","  ('made', 'by', 'PERSON'),\n","  ('made', 'on', 'DATE'),\n","  ('made', 'as', 'athletes'),\n","  ('made', 'on', 'development')],\n"," 'resulting': [('resulting', 'in', 'infertility')]}"]},"metadata":{},"execution_count":137}]},{"cell_type":"markdown","id":"a4a03652","metadata":{"id":"a4a03652"},"source":["<font color=\"red\">**[ TODO ]**</font>  Please print out all VERB-PREP-NOUN grammar patterns in rule_gp with the verb \"provide\".\n"]},{"cell_type":"code","execution_count":null,"id":"918eeda9","metadata":{"id":"918eeda9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c053b84a-03be-4bd0-ea0c-3b43272fc474"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('provided', 'by', 'T'), ('provided', 'by', 'PERSON')]"]},"metadata":{},"execution_count":138}],"source":["rule_gp['provided']"]},{"cell_type":"markdown","id":"69efbb4d","metadata":{"id":"69efbb4d"},"source":["## TA's Notes\n","\n","If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1OKbXhcv6E3FEQDPnbHEHEeHvpxv01jxugMP7WwnKqKw/edit#gid=258852025) to reserve demo time.  \n","The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to elearn. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n","<br>Note that **late submission will not be allowed**."]}],"metadata":{"kernelspec":{"display_name":"gm-transformer-venv","language":"python","name":"gm-transformer-venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}